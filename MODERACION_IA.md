# ü§ñ Implementaci√≥n de Moderaci√≥n con IA

## Tecnolog√≠a Utilizada

**OpenAI GPT-4o-mini** - Modelo de lenguaje de OpenAI para an√°lisis de contenido.
**Librer√≠a**: `ai` (AI SDK de Vercel) + `@ai-sdk/openai` - SDK para integrar OpenAI en Node.js.

## ¬øC√≥mo Funciona?

### 1. Obtener API Key de OpenAI

1. Crear cuenta en [OpenAI Platform](https://platform.openai.com/)
2. Ir a [API Keys](https://platform.openai.com/api-keys)
3. Crear nueva API key
4. Copiar la clave (solo se muestra una vez)
5. **Importante**: Agregar m√©todo de pago (costo muy bajo: ~$0.0001 por evento)

### 2. Configuraci√≥n (Backend)

**Archivo**: `.env`

```env
OPENAI_API_KEY=sk-tu_clave_de_openai_aqui
```

**Instalar dependencias**:

```bash
pnpm install ai @ai-sdk/openai zod
```

### 3. Servicio de Moderaci√≥n

**Archivo**: `src/shared/ai/contentModerator.ts`

```typescript
import { generateText } from 'ai'
import { openai } from '@ai-sdk/openai'

export interface ModerationResult {
  isInappropriate: boolean
  reason?: string
  detectedIssues?: string[]
}

export async function moderateEventContent(
  name: string,
  description: string
): Promise<ModerationResult> {
  // Construir prompt para la IA
  const prompt = `Analiza el siguiente contenido de un evento y determina si contiene lenguaje inapropiado, ofensivo, discriminatorio, violento, sexual expl√≠cito, o cualquier otro contenido inadecuado.

Nombre del evento: "${name}"
Descripci√≥n del evento: "${description}"

Responde √öNICAMENTE con un JSON en el siguiente formato:
{
  "isInappropriate": true/false,
  "reason": "breve explicaci√≥n si es inapropiado",
  "detectedIssues": ["lista", "de", "problemas", "detectados"]
}`

  // Llamar a OpenAI
  const { text } = await generateText({
    model: openai('gpt-4o-mini'), // Modelo econ√≥mico
    prompt: prompt,
    temperature: 0.3, // Baja temperatura = respuestas consistentes
  })

  // Parsear respuesta JSON
  const result: ModerationResult = JSON.parse(text)
  return result
}

export async function validateEventContent(
  name: string,
  description: string
): Promise<void> {
  const result = await moderateEventContent(name, description)

  if (result.isInappropriate) {
    let errorMessage = result.reason || 'Contenido inapropiado detectado'

    if (result.detectedIssues && result.detectedIssues.length > 0) {
      errorMessage += `. Problemas detectados: ${result.detectedIssues.join(
        ', '
      )}`
    }

    throw new Error(errorMessage)
  }
}
```

### 4. Integraci√≥n en Controller

**Archivo**: `src/evento/evento.controller.ts`

```typescript
import { validateEventContent } from '../shared/ai/contentModerator.js'

async function add(req: Request, res: Response) {
  const eventoData = req.body

  // ü§ñ MODERACI√ìN CON IA
  try {
    await validateEventContent(eventoData.name, eventoData.description)
  } catch (moderationError: any) {
    return res.status(400).json({
      success: false,
      message: 'üö´ No se puede crear el evento',
      reason: 'Contenido inapropiado detectado',
      details: moderationError.message,
    })
  }

  // Si pasa la moderaci√≥n, crear el evento
  const evento = em.create(Evento, eventoData)
  await em.persistAndFlush(evento)

  res.status(201).json(evento)
}
```

### 5. Manejo en Frontend

**Archivo**: `src/pages/EventoCreate.js`

```javascript
try {
  const response = await axios.post(
    'http://localhost:4000/api/eventos',
    formData
  )
  alert('‚úÖ Evento creado exitosamente')
  navigate('/EventosOrganizador')
} catch (error) {
  if (error.response && error.response.status === 400) {
    const errorData = error.response.data

    let errorMessage = 'üö´ No se puede crear el evento\n\n'

    if (errorData.reason) {
      errorMessage += `${errorData.reason}\n\n`
    }

    if (errorData.details) {
      errorMessage += `Detalles: ${errorData.details}`
    }

    alert(errorMessage)
    return // No navegar, mantener formulario
  }

  alert(`Error: ${error.message}`)
}
```

## Flujo Completo

```
Organizador env√≠a formulario
        ‚Üì
Backend recibe petici√≥n POST /api/eventos
        ‚Üì
Extrae nombre y descripci√≥n
        ‚Üì
Llama a moderateEventContent()
        ‚Üì
Env√≠a prompt a OpenAI GPT-4o-mini
        ‚Üì
IA analiza el contenido
        ‚Üì
Devuelve JSON con resultado
        ‚Üì
¬øEs inapropiado?
    ‚Üô        ‚Üò
  S√ç          NO
   ‚Üì           ‚Üì
Lanza error    Contin√∫a
con detalles   creaci√≥n
   ‚Üì           ‚Üì
Controller     Evento
devuelve 400   creado
   ‚Üì           ‚Üì
Frontend       Frontend
muestra        muestra
mensaje        √©xito
```

## Ejemplo de Respuestas de la IA

### Contenido Apropiado

```json
{
  "isInappropriate": false
}
```

### Contenido Inapropiado

```json
{
  "isInappropriate": true,
  "reason": "El evento contiene lenguaje ofensivo y discriminatorio",
  "detectedIssues": ["insultos", "lenguaje vulgar", "contenido discriminatorio"]
}
```

## Qu√© Detecta la IA

### ‚ùå Rechaza:

- Insultos y lenguaje ofensivo
- Discriminaci√≥n (racial, g√©nero, religi√≥n, etc.)
- Violencia expl√≠cita
- Contenido sexual inadecuado
- Lenguaje vulgar excesivo

### ‚úÖ Permite:

- Lenguaje t√©cnico (ej: "killer feature", "evento explosivo")
- T√©rminos del dominio de eventos
- Descripciones objetivas
- Referencias a pel√≠culas/juegos (ej: "Tributo a Breaking Bad")

## Configuraci√≥n del Modelo

```typescript
const { text } = await generateText({
  model: openai('gpt-4o-mini'), // Modelo r√°pido y econ√≥mico
  prompt: prompt,
  temperature: 0.3, // 0.0-1.0: m√°s bajo = m√°s consistente
})
```

### Modelos disponibles:

- `gpt-4o-mini` - Recomendado (r√°pido, econ√≥mico, preciso)
- `gpt-4o` - M√°s potente pero m√°s costoso
- `gpt-3.5-turbo` - Econ√≥mico pero menos preciso

## Costos Aproximados

**GPT-4o-mini**:

- Input: $0.150 por 1M tokens
- Output: $0.600 por 1M tokens
- **Por evento**: ~$0.0001 (1 centavo de d√≥lar cada 100 eventos)

## Failsafe (Seguridad)

Si hay un error en la IA (API ca√≠da, error de configuraci√≥n, etc.), **el sistema permite la creaci√≥n del evento** para no bloquear completamente la funcionalidad:

```typescript
try {
  // Llamar a IA
  const result = await moderateEventContent(name, description)
  return result
} catch (error) {
  console.error('Error en moderaci√≥n:', error)
  // FAILSAFE: Permitir creaci√≥n si hay error t√©cnico
  return { isInappropriate: false }
}
```

## Testing

**Archivo**: `src/test-moderacion-ia.ts`

```bash
npx ts-node src/test-moderacion-ia.ts
```

Ejecuta 4 casos de prueba:

1. ‚úÖ Evento apropiado
2. ‚ùå Evento con insultos
3. ‚ùå Evento discriminatorio
4. ‚úÖ Evento t√©cnico (permite "killer")

## Caracter√≠sticas

- ‚úÖ An√°lisis autom√°tico de contenido
- ‚úÖ Respuesta en menos de 1 segundo
- ‚úÖ Mensajes detallados con razones
- ‚úÖ Lista de problemas detectados
- ‚úÖ Failsafe si la API falla
- ‚úÖ Costo muy bajo por operaci√≥n
- ‚úÖ No bloquea t√©rminos t√©cnicos leg√≠timos

## Variables de Entorno Requeridas

```env
OPENAI_API_KEY=sk-proj-xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx
```

‚ö†Ô∏è **Sin esta variable, el sistema funcionar√° pero NO moderar√° contenido** (failsafe activo).
